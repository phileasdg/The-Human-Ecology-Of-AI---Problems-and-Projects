{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT3: Generating Text with a Language Model\n",
    "\n",
    "GPT3 is a generative language model (GPT) that is trained on a large corpus of text. It allows you to generate text from a given **context**, where the context is **a prompt** or seed **which takes the form of a sequence of words**.\n",
    "\n",
    "You can read up on how to use GPT3 here: [OpenAI documentation](https://beta.openai.com/docs/introduction/overview).\n",
    "\n",
    "Unfortunately, OpenAI's documentation does not really explain how the model works behind the scenes, so before we start playing around with it, let's fist explore some of the concepts behind it, and how it works."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How was GPT3 trained?\n",
    "\n",
    "GPT3 was trained on a large corpus of text composed of data from the following sources:\n",
    "\n",
    "| Dataset      | Quantity of Tokens | Weight in Training Mix |\n",
    "|--------------|--------------------|------------------------|\n",
    "| Common Crawl | 410 billion        |                    60% |\n",
    "| WebText2     | 19 billion         |                    22% |\n",
    "| Books1       | 12 billion         |                     8% |\n",
    "| Books2       | 55 billion         |                     8% |\n",
    "| Wikipedia    | 3 billion          |                     3% |\n",
    "\n",
    "(Source: [Language models are few-shot learners, OpenAI](https://arxiv.org/abs/2005.14165))\n",
    "\n",
    "Researchers at OpenAI used a program called a tokenizer to break the text into a series of tokens.\n",
    "\n",
    "**Tokens are common sequences of characters found in text.** You can try out OpenAI's Tokenizer [here](https://beta.openai.com/tokenizer) to get a better idea of what it does.\n",
    "\n",
    "Here is an example of generated using OpenAI's Tokenizer: A tokenisation of an excerpt from the first tablet of the Epic of Gilgamesh:\n",
    "\n",
    "<img src=\"Epic_of_Gilgamesh_excerpt_tablet_1_tokens.png\" width=\"573\"/>\n",
    "\n",
    "From the tokenized text, the model was trained using a type of deep-learning neural network architecture called a transformer. I would show you a diagram of how it works, but I think that's a bit too technical for this tutorial. If you must take a look, here's a [link to the diagram](https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png), and here's a [link to the original paper](https://arxiv.org/abs/1706.03762) which introduced the transformer architecture.\n",
    "\n",
    "Before we start playing around with the model, I have one more graph to show you:\n",
    "\n",
    "<img src=\"Human_ability_to_detect_model_generated_news_articles.png\" width=\"640\"/>\n",
    "\n",
    "(Source: [Language models are few-shot learners, OpenAI](https://arxiv.org/abs/2005.14165))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup:\n",
    "\n",
    "Let's first set up some functions in code that will help us work with GPT3 without too much fuss."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\"\"\"\n",
    "set up gpt-3 API connection\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def setup(key=\"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\"):\n",
    "    openai.api_key = key\n",
    "\n",
    "setup()\n",
    "\n",
    "\"\"\"\n",
    "get gpt-3 to continue a prompt\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_response(prompt, engine=\"davinci\", temp=0.7, max_tok=64, top_p=1, freq_pen=0, pres_pen=0,\n",
    "                 return_whole_obj=False, echo_prompt=True):\n",
    "    response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        temperature=temp,\n",
    "        max_tokens=max_tok,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=freq_pen,\n",
    "        presence_penalty=pres_pen\n",
    "    )\n",
    "    if return_whole_obj is True:\n",
    "        return response\n",
    "    else:\n",
    "        if echo_prompt is True:\n",
    "            return str(prompt + response[\"choices\"][0][\"text\"])\n",
    "        else:\n",
    "            return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "get gpt-3 to follow an instruction from a prompt\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def follow_instruction(prompt, engine=\"davinci-instruct-beta-v3\", temp=0.7, max_tok=64, top_p=1, freq_pen=0, pres_pen=0,\n",
    "                 return_whole_obj=False, echo_prompt=True):\n",
    "    response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        temperature=temp,\n",
    "        max_tokens=max_tok,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=freq_pen,\n",
    "        presence_penalty=pres_pen\n",
    "    )\n",
    "    if return_whole_obj is True:\n",
    "        return response\n",
    "    else:\n",
    "        if echo_prompt is True:\n",
    "            return str(prompt + \"\\n\" + response[\"choices\"][0][\"text\"])\n",
    "        else:\n",
    "            return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "\"\"\"\n",
    "get gpt-3 davinci-codex to continue produce python code\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def codex_response(prompt, temp=0.7, max_tok=64, top_p=1, freq_pen=0, pres_pen=0,\n",
    "                   return_whole_obj=False, echo_prompt=True):\n",
    "    prompt = str(\"\\\"\\\"\\\"\\n\" + prompt + \"\\n\\\"\\\"\\\"\")\n",
    "    response = get_response(prompt, engine=\"davinci-codex\", temp=temp, max_tok=max_tok,\n",
    "                            top_p=top_p, freq_pen=freq_pen, pres_pen=pres_pen,\n",
    "                            return_whole_obj=return_whole_obj, echo_prompt=echo_prompt)\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examples:\n",
    "\n",
    "### Getting GPT-3 to continue a prompt:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "Well well well... What do we have here?\"\n\n\n\n\"It's a girl,\" said the soldier. \"She's in their medical facility.\"\n\n\n\n\"Really?\" said the man. \"Well, well, well... you know, I never thought they could.\"\n\n\n\n\"What's that?\"\n\n\n\n\""
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = get_response(\"Well well well... What\")\n",
    "md(format(completion))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting GPT-3 to follow an instruction from a prompt:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "Tell me a joke about robots.\n\n\nWhy did the robot cross the road?\n\nTo get to the other side!"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = follow_instruction(\"Tell me a joke about robots.\")\n",
    "md(format(completion))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting GPT-3 to generate python code:\n",
    "Let's ask GPT-3 to write some code for us:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Plot a histogram of a normal distribution\n",
      "\"\"\"\n",
      "\n",
      "from numpy.random import normal, seed\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set()\n",
      "\n",
      "seed(0)\n",
      "\n",
      "# Generate a normal distribution sample\n",
      "sample = normal(size=200)\n",
      "\n",
      "# Plot a histogram\n",
      "plt.hist(sample, bins=10, density=True)\n",
      "\n",
      "# Remove axis spines\n",
      "sns.despine()\n",
      "\n",
      "plt.show()\n"
     ]
    }
   ],
   "source": [
    "completion_code = codex_response(\"Plot a histogram of a normal distribution\", max_tok=64*5)\n",
    "\n",
    "print(completion_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot a histogram of a normal distribution\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample of 1000 normally distributed data points\n",
    "mu = 500\n",
    "sigma = 80\n",
    "sample = np.random.normal(mu, sigma, 1000)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure()\n",
    "plt.hist(sample, bins=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}